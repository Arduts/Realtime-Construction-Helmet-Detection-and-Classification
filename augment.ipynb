{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import cv2 \n",
    "import os \n",
    "import pickle \n",
    "import random\n",
    "import shutil \n",
    "import uuid\n",
    "# Image augmentation \n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'Data'\n",
    "\n",
    "# Original Path \n",
    "original_train_path = os.path.join(data_path, 'train') \n",
    "original_test_path = os.path.join(data_path, 'test') \n",
    "\n",
    "# Augmented Path\n",
    "augmented_train_path = os.path.join(data_path , 'augmented_train')\n",
    "augmented_test_path = os.path.join(data_path , 'augmented_test')\n",
    "augmented_validation_path = os.path.join(data_path, 'augmented_validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Classes : blue, no helmet, not helmet, red, white, yellow'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLASSES = os.listdir(original_train_path)\n",
    "IMG_SIZE = 256\n",
    "AUGMENTATION_MULTIPLEX = 4\n",
    "'Classes : '+', '.join(CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_dir(new_data):\n",
    "  if not os.path.exists(new_data):  \n",
    "    os.mkdir(new_data)\n",
    "  else: \n",
    "    shutil.rmtree(new_data)\n",
    "    os.mkdir(new_data)\n",
    "\n",
    "def random_image_name():\n",
    "    img_name = f'{uuid.uuid4().hex}_helmet.jpg'\n",
    "    return img_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_new_dir(augmented_train_path)\n",
    "create_new_dir(augmented_test_path)\n",
    "create_new_dir(augmented_validation_path)\n",
    "\n",
    "\n",
    "def image_augmentation(save_dir, image_gen):\n",
    "  print(save_dir)\n",
    "  for image_dir in tqdm(image_gen):\n",
    "    \n",
    "    # Copy and paste original image \n",
    "    save_file_dir = os.path.join(save_train ,random_image_name())\n",
    "    shutil.copy(image_dir, save_file_dir)\n",
    "\n",
    "    # Compress and Augment images \n",
    "    img_array = cv2.imread( image_dir,cv2.COLOR_BGR2RGB)\n",
    "    img_array = cv2.normalize(img_array , None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    img_array = cv2.resize( img_array, ( 256, 256)) \n",
    "    \n",
    "    for _ in range(AUGMENTATION_MULTIPLEX):\n",
    "\n",
    "      # Augmentation properties\n",
    "\n",
    "      transform = A.Compose([\n",
    "          A.RandomCrop(width=256, height=256),\n",
    "          A.HorizontalFlip(p=0.8),\n",
    "          A.RandomBrightnessContrast(p=0.5),\n",
    "          A.RandomRotate90()\n",
    "      ])\n",
    "      \n",
    "\n",
    "      # Augment image\n",
    "      transformed = transform(image=img_array )\n",
    "      img_array_resize = cv2.resize( transformed[\"image\"], ( IMG_SIZE, IMG_SIZE))\n",
    "      save_image = cv2.convertScaleAbs(img_array_resize, alpha=(256.0))\n",
    "\n",
    "      # Save augmented image \n",
    "      save_file = os.path.join( save_dir, random_image_name())\n",
    "      cv2.imwrite(save_file , save_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\\augmented_train\\blue\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:34<00:00, 34.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\\augmented_test\\blue\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225/225 [00:07<00:00, 31.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\\augmented_validation\\blue\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:02<00:00, 30.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [ blue ] ----\n",
      "Original train:  1200\n",
      "Original test:  300\n",
      "Splitted train:  1200\n",
      "Splitted test:  225\n",
      "Splitted validation:  75\n",
      "-------------------------\n",
      "\n",
      "Data\\augmented_train\\no helmet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:32<00:00, 37.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\\augmented_test\\no helmet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225/225 [00:07<00:00, 31.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\\augmented_validation\\no helmet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:02<00:00, 31.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [ no helmet ] ----\n",
      "Original train:  1200\n",
      "Original test:  300\n",
      "Splitted train:  1200\n",
      "Splitted test:  225\n",
      "Splitted validation:  75\n",
      "-------------------------\n",
      "\n",
      "Data\\augmented_train\\not helmet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:33<00:00, 35.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\\augmented_test\\not helmet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225/225 [00:06<00:00, 32.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\\augmented_validation\\not helmet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:02<00:00, 30.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [ not helmet ] ----\n",
      "Original train:  1200\n",
      "Original test:  300\n",
      "Splitted train:  1200\n",
      "Splitted test:  225\n",
      "Splitted validation:  75\n",
      "-------------------------\n",
      "\n",
      "Data\\augmented_train\\red\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:28<00:00, 42.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\\augmented_test\\red\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225/225 [00:06<00:00, 36.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\\augmented_validation\\red\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:02<00:00, 33.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [ red ] ----\n",
      "Original train:  1200\n",
      "Original test:  300\n",
      "Splitted train:  1200\n",
      "Splitted test:  225\n",
      "Splitted validation:  75\n",
      "-------------------------\n",
      "\n",
      "Data\\augmented_train\\white\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:47<00:00, 25.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\\augmented_test\\white\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225/225 [00:11<00:00, 20.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\\augmented_validation\\white\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:03<00:00, 20.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [ white ] ----\n",
      "Original train:  1200\n",
      "Original test:  300\n",
      "Splitted train:  1200\n",
      "Splitted test:  225\n",
      "Splitted validation:  75\n",
      "-------------------------\n",
      "\n",
      "Data\\augmented_train\\yellow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:31<00:00, 37.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\\augmented_test\\yellow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225/225 [00:06<00:00, 32.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\\augmented_validation\\yellow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:02<00:00, 33.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [ yellow ] ----\n",
      "Original train:  1200\n",
      "Original test:  300\n",
      "Splitted train:  1200\n",
      "Splitted test:  225\n",
      "Splitted validation:  75\n",
      "-------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for classes in CLASSES:\n",
    "\n",
    "  # Original Train dir and Train images \n",
    "  class_train_dir = os.path.join(original_train_path, classes)\n",
    "  class_train =[ os.path.join(class_train_dir,i) for i in os.listdir(class_train_dir)]\n",
    "\n",
    "  # Original Test dir and Test imagesa \n",
    "  class_test_dir = os.path.join(original_test_path, classes)\n",
    "  class_test =  [ os.path.join(class_test_dir,i) for i in os.listdir(class_test_dir)]\n",
    "\n",
    "  # Concat and shuffle \n",
    "  images = np.array(class_train+class_test)\n",
    "  np.random.shuffle(images)\n",
    "\n",
    "  # Split the images into 3 segements ( train 80%, test 15%, validation 5% )\n",
    "  \n",
    "  train_count = int(len(images)*0.80)\n",
    "  test_count =  int(len(images)*0.15)\n",
    "  validation_count =  int(len(images)*0.05)\n",
    "\n",
    "  train = images[:train_count]\n",
    "  test = images[train_count:train_count+test_count]\n",
    "  validation = images[train_count+test_count:train_count+test_count+validation_count]\n",
    "\n",
    "  # Shufle splitted segments \n",
    "  np.random.shuffle(train)\n",
    "  np.random.shuffle(test)\n",
    "  np.random.shuffle(validation)\n",
    "\n",
    "  # Images Dir \n",
    "  save_train = os.path.join(augmented_train_path, classes)\n",
    "  save_test = os.path.join(augmented_test_path , classes)\n",
    "  save_validation = os.path.join(augmented_validation_path, classes)\n",
    "\n",
    "  if not os.path.exists(save_train): os.mkdir(save_train)\n",
    "  if not os.path.exists(save_test): os.mkdir(save_test)\n",
    "  if not os.path.exists(save_validation): os.mkdir(save_validation)\n",
    "\n",
    "  # Image augmentation \n",
    "  image_augmentation( save_train ,train)\n",
    "  image_augmentation( save_test ,test)\n",
    "  image_augmentation( save_validation,  validation)\n",
    "\n",
    "  print(f'--- [ {classes} ] ----')\n",
    "  print(f'Original train: ',len(class_train))\n",
    "  print(f'Original test: ',len(class_test))\n",
    "  print(f'Splitted train: ', len(train) )\n",
    "  print(f'Splitted test: ', len(test) )\n",
    "  print(f'Splitted validation: ', len(validation))\n",
    "  print('-------------------------\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "83d53be51f826905b77314a1c279da9dff73a13b0bbfcc7c1613a4b0dde8d3cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
